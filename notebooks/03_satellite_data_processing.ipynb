{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Satellite Data Processing for NEON AOP Crosswalk\n\nThis notebook demonstrates how to collect, process, and prepare satellite data (Sentinel-2 and Landsat) for the AOP crosswalk analysis. We'll focus on extracting vegetation indices and preparing data that aligns with our NEON AOP sites.\n\n## Key Learning Objectives\n- Collect satellite imagery using Google Earth Engine\n- Extract vegetation indices (NDVI, NBR, NDWI, EVI)\n- Handle cloud masking and quality filtering\n- Prepare data for crosswalk with AOP measurements\n- Visualize satellite data coverage and quality",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## 1. Setup and Imports\n\nFirst, let's import all necessary libraries and initialize our environment for satellite data processing.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import required libraries\nimport ee\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport folium\nfrom folium import plugins\nfrom datetime import datetime, timedelta\nimport json\nimport os\nfrom typing import Dict, List, Tuple, Optional\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set up plotting style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n\n# Configure matplotlib for inline display\n%matplotlib inline",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 2. Initialize Google Earth Engine\n\nInitialize Earth Engine and test the connection. This requires authentication if running for the first time.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Initialize Earth Engine\ntry:\n    ee.Initialize()\n    print(\"‚úÖ Earth Engine initialized successfully!\")\nexcept Exception as e:\n    print(\"‚ùå Earth Engine initialization failed. Running authentication...\")\n    ee.Authenticate()\n    ee.Initialize()\n    print(\"‚úÖ Earth Engine initialized after authentication!\")\n\n# Test the connection with a simple query\ntest_image = ee.Image(\"LANDSAT/LC08/C02/T1_L2/LC08_044034_20200318\")\nprint(f\"Test image bands: {test_image.bandNames().getInfo()}\")\nprint(\"‚úÖ Earth Engine connection verified!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3. Define Target Sites\n\nWe'll work with both fire case study sites and baseline sites to understand the crosswalk performance across different conditions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Define NEON sites with their locations and characteristics\nNEON_SITES = {\n    # Fire Case Study Sites\n    'GRSM': {\n        'name': 'Great Smoky Mountains',\n        'lat': 35.6889,\n        'lon': -83.5019,\n        'type': 'fire_case_study',\n        'fire_year': 2016,\n        'description': 'Chimney Tops 2 Fire (Nov-Dec 2016)'\n    },\n    'SOAP': {\n        'name': 'Soaproot Saddle',\n        'lat': 37.0334,\n        'lon': -119.2622,\n        'type': 'fire_case_study',\n        'fire_year': 2020,\n        'description': 'Creek Fire (Sep-Dec 2020)'\n    },\n    'SYCA': {\n        'name': 'Sycamore Creek',\n        'lat': 33.7514,\n        'lon': -111.5069,\n        'type': 'fire_case_study',\n        'fire_year': 2024,\n        'description': 'Contemporary fire event'\n    },\n    # Baseline Sites\n    'SRER': {\n        'name': 'Santa Rita Experimental Range',\n        'lat': 31.9107,\n        'lon': -110.8355,\n        'type': 'baseline',\n        'description': 'Desert grassland/shrubland'\n    },\n    'JORN': {\n        'name': 'Jornada LTER',\n        'lat': 32.5907,\n        'lon': -106.8426,\n        'type': 'baseline',\n        'description': 'Desert shrubland'\n    },\n    'ONAQ': {\n        'name': 'Onaqui-Ault',\n        'lat': 40.1776,\n        'lon': -112.4524,\n        'type': 'baseline',\n        'description': 'Desert shrubland'\n    },\n    'SJER': {\n        'name': 'San Joaquin Experimental Range',\n        'lat': 37.1088,\n        'lon': -119.7323,\n        'type': 'baseline',\n        'description': 'Oak woodland/grassland'\n    }\n}\n\n# Create a DataFrame for easy reference\nsites_df = pd.DataFrame.from_dict(NEON_SITES, orient='index')\nprint(\"NEON Sites Summary:\")\nprint(sites_df[['name', 'type', 'description']])\n\n# Separate fire and baseline sites\nfire_sites = [site for site, info in NEON_SITES.items() if info['type'] == 'fire_case_study']\nbaseline_sites = [site for site, info in NEON_SITES.items() if info['type'] == 'baseline']\nprint(f\"\\nüî• Fire case study sites: {', '.join(fire_sites)}\")\nprint(f\"üåø Baseline sites: {', '.join(baseline_sites)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualize site locations on an interactive map\ndef create_sites_map(sites_dict):\n    \"\"\"Create a folium map showing all NEON sites\"\"\"\n    # Calculate center of all sites\n    lats = [info['lat'] for info in sites_dict.values()]\n    lons = [info['lon'] for info in sites_dict.values()]\n    center_lat = np.mean(lats)\n    center_lon = np.mean(lons)\n    \n    # Create map\n    m = folium.Map(location=[center_lat, center_lon], zoom_start=5)\n    \n    # Add sites to map\n    for site_code, info in sites_dict.items():\n        color = 'red' if info['type'] == 'fire_case_study' else 'green'\n        icon = 'fire' if info['type'] == 'fire_case_study' else 'leaf'\n        \n        folium.Marker(\n            location=[info['lat'], info['lon']],\n            popup=f\"<b>{site_code}: {info['name']}</b><br>{info['description']}\",\n            tooltip=f\"{site_code}: {info['name']}\",\n            icon=folium.Icon(color=color, icon=icon, prefix='fa')\n        ).add_to(m)\n    \n    return m\n\n# Create and display the map\nsites_map = create_sites_map(NEON_SITES)\nprint(\"Interactive map of NEON sites:\")\nsites_map",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 4. Sentinel-2 Data Collection with Cloud Masking\n\nNow let's collect Sentinel-2 imagery for our target sites. We'll implement cloud masking to ensure high-quality data.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Define cloud masking function for Sentinel-2\ndef mask_s2_clouds(image):\n    \"\"\"\n    Cloud masking function for Sentinel-2 imagery using QA60 band\n    \"\"\"\n    qa = image.select('QA60')\n    \n    # Bits 10 and 11 are clouds and cirrus, respectively\n    cloud_bit_mask = 1 << 10\n    cirrus_bit_mask = 1 << 11\n    \n    # Both flags should be set to zero, indicating clear conditions\n    mask = qa.bitwiseAnd(cloud_bit_mask).eq(0).And(\n        qa.bitwiseAnd(cirrus_bit_mask).eq(0)\n    )\n    \n    return image.updateMask(mask).divide(10000).copyProperties(image, ['system:time_start'])\n\n# Function to calculate vegetation indices\ndef add_vegetation_indices(image):\n    \"\"\"\n    Add NDVI, NBR, NDWI, and EVI to Sentinel-2 image\n    \"\"\"\n    # Band names for Sentinel-2\n    nir = image.select('B8')\n    red = image.select('B4')\n    green = image.select('B3')\n    blue = image.select('B2')\n    swir1 = image.select('B11')\n    swir2 = image.select('B12')\n    \n    # NDVI = (NIR - Red) / (NIR + Red)\n    ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI')\n    \n    # NBR = (NIR - SWIR2) / (NIR + SWIR2)\n    nbr = nir.subtract(swir2).divide(nir.add(swir2)).rename('NBR')\n    \n    # NDWI = (Green - NIR) / (Green + NIR)\n    ndwi = green.subtract(nir).divide(green.add(nir)).rename('NDWI')\n    \n    # EVI = 2.5 * ((NIR - Red) / (NIR + 6 * Red - 7.5 * Blue + 1))\n    evi = nir.subtract(red).divide(\n        nir.add(red.multiply(6)).subtract(blue.multiply(7.5)).add(1)\n    ).multiply(2.5).rename('EVI')\n    \n    return image.addBands([ndvi, nbr, ndwi, evi])\n\n# Function to get Sentinel-2 collection for a site\ndef get_sentinel2_collection(site_code, start_date, end_date, buffer_km=5):\n    \"\"\"\n    Get Sentinel-2 image collection for a specific site and date range\n    \"\"\"\n    site_info = NEON_SITES[site_code]\n    \n    # Create a point and buffer\n    point = ee.Geometry.Point([site_info['lon'], site_info['lat']])\n    area = point.buffer(buffer_km * 1000)  # Convert km to meters\n    \n    # Get Sentinel-2 collection\n    collection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n        .filterBounds(area) \\\n        .filterDate(start_date, end_date) \\\n        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)) \\\n        .map(mask_s2_clouds) \\\n        .map(add_vegetation_indices) \\\n        .select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12', 'NDVI', 'NBR', 'NDWI', 'EVI'])\n    \n    return collection, area\n\n# Example: Get data for GRSM site around the fire event\nsite = 'GRSM'\nfire_year = NEON_SITES[site]['fire_year']\n\n# Define date ranges for pre and post fire\npre_fire_start = f'{fire_year}-06-01'\npre_fire_end = f'{fire_year}-10-31'\npost_fire_start = f'{fire_year + 1}-06-01'\npost_fire_end = f'{fire_year + 1}-10-31'\n\n# Get collections\npre_fire_col, area = get_sentinel2_collection(site, pre_fire_start, pre_fire_end)\npost_fire_col, _ = get_sentinel2_collection(site, post_fire_start, post_fire_end)\n\nprint(f\"üìä Sentinel-2 data for {site} ({NEON_SITES[site]['name']}):\")\nprint(f\"Pre-fire images ({pre_fire_start} to {pre_fire_end}): {pre_fire_col.size().getInfo()}\")\nprint(f\"Post-fire images ({post_fire_start} to {post_fire_end}): {post_fire_col.size().getInfo()}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 5. Landsat Data Collection\n\nLet's also collect Landsat 8/9 data for comparison with Sentinel-2. Landsat provides longer historical coverage which is valuable for fire studies.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Define cloud masking function for Landsat\ndef mask_landsat_clouds(image):\n    \"\"\"\n    Cloud masking function for Landsat 8/9 using QA_PIXEL band\n    \"\"\"\n    qa = image.select('QA_PIXEL')\n    \n    # Bits: 3 = cloud, 4 = cloud shadow\n    cloud_bit = 1 << 3\n    shadow_bit = 1 << 4\n    \n    # Both flags should be set to zero, indicating clear conditions\n    mask = qa.bitwiseAnd(cloud_bit).eq(0).And(\n        qa.bitwiseAnd(shadow_bit).eq(0)\n    )\n    \n    # Scale the data\n    optical_bands = image.select(['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']).multiply(0.0000275).add(-0.2)\n    \n    return image.addBands(optical_bands, None, True).updateMask(mask).copyProperties(image, ['system:time_start'])\n\n# Function to add vegetation indices for Landsat\ndef add_landsat_indices(image):\n    \"\"\"\n    Add vegetation indices to Landsat image\n    \"\"\"\n    # Band names for Landsat 8/9\n    nir = image.select('SR_B5')  # Near Infrared\n    red = image.select('SR_B4')  # Red\n    green = image.select('SR_B3')  # Green\n    blue = image.select('SR_B2')  # Blue\n    swir1 = image.select('SR_B6')  # SWIR1\n    swir2 = image.select('SR_B7')  # SWIR2\n    \n    # Calculate indices\n    ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI')\n    nbr = nir.subtract(swir2).divide(nir.add(swir2)).rename('NBR')\n    ndwi = green.subtract(nir).divide(green.add(nir)).rename('NDWI')\n    evi = nir.subtract(red).divide(\n        nir.add(red.multiply(6)).subtract(blue.multiply(7.5)).add(1)\n    ).multiply(2.5).rename('EVI')\n    \n    return image.addBands([ndvi, nbr, ndwi, evi])\n\n# Function to get Landsat collection\ndef get_landsat_collection(site_code, start_date, end_date, buffer_km=5):\n    \"\"\"\n    Get Landsat 8/9 collection for a specific site and date range\n    \"\"\"\n    site_info = NEON_SITES[site_code]\n    \n    # Create a point and buffer\n    point = ee.Geometry.Point([site_info['lon'], site_info['lat']])\n    area = point.buffer(buffer_km * 1000)\n    \n    # Combine Landsat 8 and 9\n    landsat8 = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n        .filterBounds(area) \\\n        .filterDate(start_date, end_date) \\\n        .map(mask_landsat_clouds) \\\n        .map(add_landsat_indices)\n    \n    landsat9 = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2') \\\n        .filterBounds(area) \\\n        .filterDate(start_date, end_date) \\\n        .map(mask_landsat_clouds) \\\n        .map(add_landsat_indices)\n    \n    # Merge collections\n    collection = landsat8.merge(landsat9) \\\n        .select(['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7', 'NDVI', 'NBR', 'NDWI', 'EVI'])\n    \n    return collection, area\n\n# Get Landsat data for the same site and time periods\nlandsat_pre, _ = get_landsat_collection(site, pre_fire_start, pre_fire_end)\nlandsat_post, _ = get_landsat_collection(site, post_fire_start, post_fire_end)\n\nprint(f\"\\nüìä Landsat 8/9 data for {site}:\")\nprint(f\"Pre-fire images: {landsat_pre.size().getInfo()}\")\nprint(f\"Post-fire images: {landsat_post.size().getInfo()}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Multi-Sensor Comparison\n\nLet's compare the temporal coverage and quality between Sentinel-2 and Landsat data.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Function to extract time series for a collection\ndef extract_time_series(collection, geometry, scale=30):\n    \"\"\"\n    Extract mean values for vegetation indices over time\n    \"\"\"\n    def extract_values(image):\n        # Compute mean values for the geometry\n        values = image.reduceRegion(\n            reducer=ee.Reducer.mean(),\n            geometry=geometry,\n            scale=scale,\n            maxPixels=1e9\n        )\n        \n        # Add time property\n        return ee.Feature(None, values).set('system:time_start', image.get('system:time_start'))\n    \n    # Map over collection and extract values\n    features = collection.map(extract_values)\n    \n    # Convert to pandas DataFrame\n    data = features.getInfo()\n    \n    if data['features']:\n        df = pd.DataFrame([f['properties'] for f in data['features']])\n        df['date'] = pd.to_datetime(df['system:time_start'], unit='ms')\n        df = df.sort_values('date')\n        return df\n    else:\n        return pd.DataFrame()\n\n# Extract time series for both sensors\nprint(\"Extracting time series data...\")\npoint_geom = ee.Geometry.Point([NEON_SITES[site]['lon'], NEON_SITES[site]['lat']]).buffer(1000)\n\n# Sentinel-2 time series\ns2_pre_ts = extract_time_series(pre_fire_col.select(['NDVI', 'NBR']), point_geom)\ns2_post_ts = extract_time_series(post_fire_col.select(['NDVI', 'NBR']), point_geom)\n\n# Landsat time series\nls_pre_ts = extract_time_series(landsat_pre.select(['NDVI', 'NBR']), point_geom)\nls_post_ts = extract_time_series(landsat_post.select(['NDVI', 'NBR']), point_geom)\n\nprint(f\"‚úÖ Time series extracted successfully!\")\n\n# Create comparison plot\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\nfig.suptitle(f'Multi-Sensor Comparison for {site} ({NEON_SITES[site][\"name\"]})', fontsize=16)\n\n# NDVI comparison\nax = axes[0, 0]\nif not s2_pre_ts.empty:\n    ax.scatter(s2_pre_ts['date'], s2_pre_ts['NDVI'], label='Sentinel-2', alpha=0.7, s=50)\nif not ls_pre_ts.empty:\n    ax.scatter(ls_pre_ts['date'], ls_pre_ts['NDVI'], label='Landsat', alpha=0.7, s=50)\nax.set_title('Pre-Fire NDVI')\nax.set_ylabel('NDVI')\nax.legend()\nax.grid(True, alpha=0.3)\n\nax = axes[0, 1]\nif not s2_post_ts.empty:\n    ax.scatter(s2_post_ts['date'], s2_post_ts['NDVI'], label='Sentinel-2', alpha=0.7, s=50)\nif not ls_post_ts.empty:\n    ax.scatter(ls_post_ts['date'], ls_post_ts['NDVI'], label='Landsat', alpha=0.7, s=50)\nax.set_title('Post-Fire NDVI')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# NBR comparison\nax = axes[1, 0]\nif not s2_pre_ts.empty:\n    ax.scatter(s2_pre_ts['date'], s2_pre_ts['NBR'], label='Sentinel-2', alpha=0.7, s=50)\nif not ls_pre_ts.empty:\n    ax.scatter(ls_pre_ts['date'], ls_pre_ts['NBR'], label='Landsat', alpha=0.7, s=50)\nax.set_title('Pre-Fire NBR')\nax.set_ylabel('NBR')\nax.set_xlabel('Date')\nax.legend()\nax.grid(True, alpha=0.3)\n\nax = axes[1, 1]\nif not s2_post_ts.empty:\n    ax.scatter(s2_post_ts['date'], s2_post_ts['NBR'], label='Sentinel-2', alpha=0.7, s=50)\nif not ls_post_ts.empty:\n    ax.scatter(ls_post_ts['date'], ls_post_ts['NBR'], label='Landsat', alpha=0.7, s=50)\nax.set_title('Post-Fire NBR')\nax.set_xlabel('Date')\nax.legend()\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Summary statistics\nprint(\"\\nüìä Data Coverage Summary:\")\nprint(f\"Sentinel-2 temporal resolution: ~5 days\")\nprint(f\"Landsat temporal resolution: ~16 days\")\nprint(f\"Sentinel-2 spatial resolution: 10-20m\")\nprint(f\"Landsat spatial resolution: 30m\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 7. Fire Impact Analysis using NBR\n\nThe Normalized Burn Ratio (NBR) is particularly effective for mapping fire severity. Let's calculate the differenced NBR (dNBR) to assess fire impact.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Calculate dNBR (differenced Normalized Burn Ratio)\ndef calculate_dnbr(pre_fire_collection, post_fire_collection):\n    \"\"\"\n    Calculate dNBR = pre-fire NBR - post-fire NBR\n    Higher values indicate greater fire severity\n    \"\"\"\n    # Get median composites\n    pre_nbr = pre_fire_collection.select('NBR').median()\n    post_nbr = post_fire_collection.select('NBR').median()\n    \n    # Calculate dNBR\n    dnbr = pre_nbr.subtract(post_nbr).rename('dNBR')\n    \n    # Add severity classification\n    # USGS fire severity thresholds\n    severity = ee.Image(0) \\\n        .where(dnbr.gt(0.1).And(dnbr.lte(0.27)), 1) \\\n        .where(dnbr.gt(0.27).And(dnbr.lte(0.44)), 2) \\\n        .where(dnbr.gt(0.44).And(dnbr.lte(0.66)), 3) \\\n        .where(dnbr.gt(0.66), 4) \\\n        .rename('severity')\n    \n    return dnbr, severity\n\n# Calculate dNBR for Sentinel-2\ns2_dnbr, s2_severity = calculate_dnbr(pre_fire_col, post_fire_col)\n\n# Create visualization parameters\ndnbr_viz = {\n    'min': -0.2,\n    'max': 0.8,\n    'palette': ['green', 'yellow', 'orange', 'red', 'darkred']\n}\n\nseverity_viz = {\n    'min': 0,\n    'max': 4,\n    'palette': ['white', 'yellow', 'orange', 'red', 'darkred']\n}\n\n# Create fire impact map\ndef create_fire_impact_map(dnbr_image, severity_image, site_info, buffer_km=10):\n    \"\"\"Create an interactive map showing fire impact\"\"\"\n    # Get the center point\n    center_lat = site_info['lat']\n    center_lon = site_info['lon']\n    \n    # Create map\n    m = folium.Map(location=[center_lat, center_lon], zoom_start=12)\n    \n    # Add dNBR layer\n    dnbr_mapid = dnbr_image.getMapId(dnbr_viz)\n    folium.TileLayer(\n        tiles=dnbr_mapid['tile_fetcher'].url_format,\n        attr='Google Earth Engine',\n        name='dNBR (Fire Impact)',\n        overlay=True,\n        control=True\n    ).add_to(m)\n    \n    # Add severity layer\n    severity_mapid = severity_image.getMapId(severity_viz)\n    folium.TileLayer(\n        tiles=severity_mapid['tile_fetcher'].url_format,\n        attr='Google Earth Engine',\n        name='Fire Severity Classes',\n        overlay=True,\n        control=True,\n        opacity=0.7\n    ).add_to(m)\n    \n    # Add site marker\n    folium.Marker(\n        location=[center_lat, center_lon],\n        popup=f\"<b>{site}: {site_info['name']}</b><br>{site_info['description']}\",\n        icon=folium.Icon(color='red', icon='fire', prefix='fa')\n    ).add_to(m)\n    \n    # Add layer control\n    folium.LayerControl().add_to(m)\n    \n    # Add legend\n    legend_html = '''\n    <div style=\"position: fixed; \n                bottom: 50px; left: 50px; width: 200px; height: 150px; \n                background-color: white; z-index:9999; font-size:14px;\n                border:2px solid grey; padding: 10px\">\n    <p align=\"center\"><b>Fire Severity</b></p>\n    <p style=\"margin: 0;\"><span style=\"color: white;\">‚¨§</span> Unburned</p>\n    <p style=\"margin: 0;\"><span style=\"color: yellow;\">‚¨§</span> Low severity</p>\n    <p style=\"margin: 0;\"><span style=\"color: orange;\">‚¨§</span> Moderate-low</p>\n    <p style=\"margin: 0;\"><span style=\"color: red;\">‚¨§</span> Moderate-high</p>\n    <p style=\"margin: 0;\"><span style=\"color: darkred;\">‚¨§</span> High severity</p>\n    </div>\n    '''\n    m.get_root().html.add_child(folium.Element(legend_html))\n    \n    return m\n\n# Create fire impact map\nfire_map = create_fire_impact_map(s2_dnbr, s2_severity, NEON_SITES[site])\nprint(f\"Fire impact map for {site} ({NEON_SITES[site]['name']}):\")\nfire_map\n\n# Calculate fire impact statistics\nstats = s2_dnbr.reduceRegion(\n    reducer=ee.Reducer.percentile([10, 25, 50, 75, 90]).combine(\n        ee.Reducer.mean(), sharedInputs=True\n    ).combine(\n        ee.Reducer.stdDev(), sharedInputs=True\n    ),\n    geometry=area,\n    scale=30,\n    maxPixels=1e9\n).getInfo()\n\nprint(f\"\\nüî• Fire Impact Statistics (dNBR):\")\nprint(f\"Mean dNBR: {stats.get('dNBR_mean', 0):.3f}\")\nprint(f\"Std Dev: {stats.get('dNBR_stdDev', 0):.3f}\")\nprint(f\"10th percentile: {stats.get('dNBR_p10', 0):.3f}\")\nprint(f\"Median (50th): {stats.get('dNBR_p50', 0):.3f}\")\nprint(f\"90th percentile: {stats.get('dNBR_p90', 0):.3f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 8. Multi-Site Processing\n\nLet's process data for all sites to compare fire-impacted and baseline conditions.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Process all sites\ndef process_site_data(site_code, year=2023, sensor='sentinel2'):\n    \"\"\"\n    Process satellite data for a given site and year\n    \"\"\"\n    site_info = NEON_SITES[site_code]\n    \n    # Define date range (growing season)\n    start_date = f'{year}-05-01'\n    end_date = f'{year}-09-30'\n    \n    # Get collection based on sensor\n    if sensor == 'sentinel2':\n        collection, area = get_sentinel2_collection(site_code, start_date, end_date)\n    else:\n        collection, area = get_landsat_collection(site_code, start_date, end_date)\n    \n    # Calculate median composite\n    median_composite = collection.median()\n    \n    # Extract statistics\n    stats = median_composite.select(['NDVI', 'NBR', 'NDWI', 'EVI']).reduceRegion(\n        reducer=ee.Reducer.mean(),\n        geometry=area,\n        scale=30,\n        maxPixels=1e9\n    ).getInfo()\n    \n    # Add site info\n    stats['site'] = site_code\n    stats['site_name'] = site_info['name']\n    stats['site_type'] = site_info['type']\n    stats['year'] = year\n    stats['sensor'] = sensor\n    stats['n_images'] = collection.size().getInfo()\n    \n    return stats\n\n# Process all sites for 2023 (or most recent available year)\nprint(\"Processing data for all sites...\")\nall_site_data = []\n\nfor site_code in NEON_SITES.keys():\n    try:\n        # Use 2023 for baseline sites, adjust for fire sites based on their fire year\n        if NEON_SITES[site_code]['type'] == 'baseline':\n            year = 2023\n        else:\n            # For fire sites, use a recent year after the fire\n            fire_year = NEON_SITES[site_code].get('fire_year', 2020)\n            year = min(2023, fire_year + 2)  # 2 years post-fire or 2023, whichever is earlier\n        \n        # Process Sentinel-2 data\n        s2_stats = process_site_data(site_code, year, 'sentinel2')\n        all_site_data.append(s2_stats)\n        print(f\"‚úÖ Processed {site_code} for year {year}\")\n        \n    except Exception as e:\n        print(f\"‚ùå Error processing {site_code}: {str(e)}\")\n\n# Convert to DataFrame\nsite_stats_df = pd.DataFrame(all_site_data)\n\n# Display summary statistics\nprint(\"\\nüìä Multi-Site Vegetation Index Summary:\")\nprint(site_stats_df[['site', 'site_name', 'site_type', 'NDVI', 'NBR', 'n_images']].round(3))\n\n# Create comparison plot\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\nfig.suptitle('Vegetation Indices Across NEON Sites', fontsize=16)\n\n# Plot each index\nindices = ['NDVI', 'NBR', 'NDWI', 'EVI']\nfor idx, vi in enumerate(indices):\n    ax = axes[idx // 2, idx % 2]\n    \n    # Separate by site type\n    fire_data = site_stats_df[site_stats_df['site_type'] == 'fire_case_study']\n    baseline_data = site_stats_df[site_stats_df['site_type'] == 'baseline']\n    \n    # Plot\n    x_fire = range(len(fire_data))\n    x_baseline = range(len(fire_data), len(fire_data) + len(baseline_data))\n    \n    ax.bar(x_fire, fire_data[vi], color='orangered', alpha=0.7, label='Fire sites')\n    ax.bar(x_baseline, baseline_data[vi], color='forestgreen', alpha=0.7, label='Baseline sites')\n    \n    # Labels\n    ax.set_xticks(range(len(site_stats_df)))\n    ax.set_xticklabels(site_stats_df['site'], rotation=45, ha='right')\n    ax.set_ylabel(vi)\n    ax.set_title(f'{vi} by Site')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Statistical comparison\nprint(\"\\nüìä Statistical Comparison:\")\nprint(\"Fire Sites (mean ¬± std):\")\nfire_means = site_stats_df[site_stats_df['site_type'] == 'fire_case_study'][indices].mean()\nfire_stds = site_stats_df[site_stats_df['site_type'] == 'fire_case_study'][indices].std()\nfor vi in indices:\n    print(f\"  {vi}: {fire_means[vi]:.3f} ¬± {fire_stds[vi]:.3f}\")\n\nprint(\"\\nBaseline Sites (mean ¬± std):\")\nbaseline_means = site_stats_df[site_stats_df['site_type'] == 'baseline'][indices].mean()\nbaseline_stds = site_stats_df[site_stats_df['site_type'] == 'baseline'][indices].std()\nfor vi in indices:\n    print(f\"  {vi}: {baseline_means[vi]:.3f} ¬± {baseline_stds[vi]:.3f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 9. Export Processed Data\n\nLet's export our processed satellite data for use in the crosswalk analysis.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Export functions for satellite data\ndef export_to_drive(image, description, folder, scale=30, region=None):\n    \"\"\"\n    Export an image to Google Drive\n    \"\"\"\n    task = ee.batch.Export.image.toDrive(\n        image=image,\n        description=description,\n        folder=folder,\n        scale=scale,\n        region=region,\n        maxPixels=1e13\n    )\n    task.start()\n    return task\n\ndef prepare_crosswalk_data(site_code, year, buffer_km=5):\n    \"\"\"\n    Prepare satellite data for crosswalk analysis\n    \"\"\"\n    # Get site info\n    site_info = NEON_SITES[site_code]\n    \n    # Define date range\n    start_date = f'{year}-05-01'\n    end_date = f'{year}-09-30'\n    \n    # Get both Sentinel-2 and Landsat collections\n    s2_col, area = get_sentinel2_collection(site_code, start_date, end_date)\n    ls_col, _ = get_landsat_collection(site_code, start_date, end_date)\n    \n    # Create median composites\n    s2_median = s2_col.median()\n    ls_median = ls_col.median()\n    \n    # Stack all bands and indices\n    s2_export = s2_median.select(['B2', 'B3', 'B4', 'B8', 'NDVI', 'NBR', 'NDWI', 'EVI'])\n    ls_export = ls_median.select(['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'NDVI', 'NBR', 'NDWI', 'EVI'])\n    \n    return {\n        'sentinel2': s2_export,\n        'landsat': ls_export,\n        'area': area,\n        'site_info': site_info\n    }\n\n# Example: Export data for one site\nexport_site = 'GRSM'\nexport_year = 2023\n\nprint(f\"Preparing export for {export_site}...\")\nexport_data = prepare_crosswalk_data(export_site, export_year)\n\n# Export to Drive (uncomment to run)\n# export_folder = 'NEON_AOP_Crosswalk'\n# s2_task = export_to_drive(\n#     export_data['sentinel2'],\n#     f'Sentinel2_{export_site}_{export_year}',\n#     export_folder,\n#     scale=10,\n#     region=export_data['area']\n# )\n# print(f\"‚úÖ Sentinel-2 export task started for {export_site}\")\n\n# Save site statistics locally\noutput_dir = '../data/processed/satellite'\nos.makedirs(output_dir, exist_ok=True)\n\n# Save the multi-site statistics\noutput_file = os.path.join(output_dir, 'multi_site_vegetation_indices.csv')\nsite_stats_df.to_csv(output_file, index=False)\nprint(f\"\\n‚úÖ Saved multi-site statistics to: {output_file}\")\n\n# Save fire impact analysis results\nfire_impact_results = {\n    'site': site,\n    'fire_year': NEON_SITES[site]['fire_year'],\n    'pre_fire_dates': f'{pre_fire_start} to {pre_fire_end}',\n    'post_fire_dates': f'{post_fire_start} to {post_fire_end}',\n    'dnbr_stats': stats,\n    'n_pre_fire_images': pre_fire_col.size().getInfo(),\n    'n_post_fire_images': post_fire_col.size().getInfo()\n}\n\nfire_impact_file = os.path.join(output_dir, f'fire_impact_{site}.json')\nwith open(fire_impact_file, 'w') as f:\n    json.dump(fire_impact_results, f, indent=2)\nprint(f\"‚úÖ Saved fire impact analysis to: {fire_impact_file}\")\n\nprint(\"\\nüìä Export Summary:\")\nprint(f\"- Multi-site vegetation indices saved to CSV\")\nprint(f\"- Fire impact analysis saved for {site}\")\nprint(f\"- Data ready for crosswalk analysis with AOP data\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Create comprehensive visualization dashboard\ndef create_dashboard():\n    \"\"\"Create a multi-panel dashboard for satellite data analysis\"\"\"\n    \n    fig = plt.figure(figsize=(20, 15))\n    gs = fig.add_gridspec(4, 3, hspace=0.3, wspace=0.3)\n    \n    # Title\n    fig.suptitle('NEON AOP Crosswalk: Satellite Data Processing Dashboard', fontsize=20, y=0.98)\n    \n    # 1. Site locations map placeholder\n    ax1 = fig.add_subplot(gs[0, :2])\n    ax1.text(0.5, 0.5, 'Interactive Site Map\\n(See folium map above)', \n             ha='center', va='center', fontsize=14, alpha=0.7)\n    ax1.set_title('NEON Site Locations', fontsize=16)\n    ax1.axis('off')\n    \n    # 2. Data coverage summary\n    ax2 = fig.add_subplot(gs[0, 2])\n    coverage_data = site_stats_df.groupby('site_type')['n_images'].mean()\n    ax2.bar(coverage_data.index, coverage_data.values, \n            color=['orangered', 'forestgreen'], alpha=0.7)\n    ax2.set_title('Average Image Coverage by Site Type', fontsize=14)\n    ax2.set_ylabel('Number of Images')\n    ax2.grid(True, alpha=0.3)\n    \n    # 3. Vegetation indices by site type\n    ax3 = fig.add_subplot(gs[1, :])\n    indices_comparison = site_stats_df.groupby('site_type')[indices].mean()\n    x = np.arange(len(indices))\n    width = 0.35\n    \n    bars1 = ax3.bar(x - width/2, indices_comparison.loc['fire_case_study'], \n                     width, label='Fire Sites', color='orangered', alpha=0.7)\n    bars2 = ax3.bar(x + width/2, indices_comparison.loc['baseline'], \n                     width, label='Baseline Sites', color='forestgreen', alpha=0.7)\n    \n    ax3.set_xlabel('Vegetation Index')\n    ax3.set_ylabel('Mean Value')\n    ax3.set_title('Average Vegetation Indices: Fire vs Baseline Sites', fontsize=16)\n    ax3.set_xticks(x)\n    ax3.set_xticklabels(indices)\n    ax3.legend()\n    ax3.grid(True, alpha=0.3)\n    \n    # Add value labels on bars\n    for bars in [bars1, bars2]:\n        for bar in bars:\n            height = bar.get_height()\n            ax3.annotate(f'{height:.3f}',\n                        xy=(bar.get_x() + bar.get_width() / 2, height),\n                        xytext=(0, 3),\n                        textcoords=\"offset points\",\n                        ha='center', va='bottom')\n    \n    # 4. NDVI distribution\n    ax4 = fig.add_subplot(gs[2, 0])\n    fire_ndvi = site_stats_df[site_stats_df['site_type'] == 'fire_case_study']['NDVI']\n    baseline_ndvi = site_stats_df[site_stats_df['site_type'] == 'baseline']['NDVI']\n    \n    ax4.hist(fire_ndvi, bins=10, alpha=0.7, label='Fire Sites', color='orangered', density=True)\n    ax4.hist(baseline_ndvi, bins=10, alpha=0.7, label='Baseline Sites', color='forestgreen', density=True)\n    ax4.set_xlabel('NDVI')\n    ax4.set_ylabel('Density')\n    ax4.set_title('NDVI Distribution', fontsize=14)\n    ax4.legend()\n    ax4.grid(True, alpha=0.3)\n    \n    # 5. NBR distribution\n    ax5 = fig.add_subplot(gs[2, 1])\n    fire_nbr = site_stats_df[site_stats_df['site_type'] == 'fire_case_study']['NBR']\n    baseline_nbr = site_stats_df[site_stats_df['site_type'] == 'baseline']['NBR']\n    \n    ax5.hist(fire_nbr, bins=10, alpha=0.7, label='Fire Sites', color='orangered', density=True)\n    ax5.hist(baseline_nbr, bins=10, alpha=0.7, label='Baseline Sites', color='forestgreen', density=True)\n    ax5.set_xlabel('NBR')\n    ax5.set_ylabel('Density')\n    ax5.set_title('NBR Distribution', fontsize=14)\n    ax5.legend()\n    ax5.grid(True, alpha=0.3)\n    \n    # 6. Correlation matrix\n    ax6 = fig.add_subplot(gs[2, 2])\n    corr_matrix = site_stats_df[indices].corr()\n    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, ax=ax6)\n    ax6.set_title('Vegetation Index Correlations', fontsize=14)\n    \n    # 7. Time series example (if available)\n    ax7 = fig.add_subplot(gs[3, :2])\n    if not s2_pre_ts.empty and not s2_post_ts.empty:\n        # Combine pre and post fire data\n        ax7.scatter(s2_pre_ts['date'], s2_pre_ts['NDVI'], \n                   label='Pre-fire', color='green', alpha=0.7, s=50)\n        ax7.scatter(s2_post_ts['date'], s2_post_ts['NDVI'], \n                   label='Post-fire', color='red', alpha=0.7, s=50)\n        \n        # Add fire event line\n        fire_date = datetime(fire_year, 11, 30)  # Approximate fire date\n        ax7.axvline(fire_date, color='orange', linestyle='--', linewidth=2, \n                   label='Fire Event')\n        \n        ax7.set_xlabel('Date')\n        ax7.set_ylabel('NDVI')\n        ax7.set_title(f'NDVI Time Series: {site} Fire Event', fontsize=14)\n        ax7.legend()\n        ax7.grid(True, alpha=0.3)\n        \n        # Format x-axis\n        import matplotlib.dates as mdates\n        ax7.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n        plt.setp(ax7.xaxis.get_majorticklabels(), rotation=45, ha='right')\n    else:\n        ax7.text(0.5, 0.5, 'Time Series Data\\n(Run cells above to populate)', \n                ha='center', va='center', fontsize=14, alpha=0.7)\n        ax7.axis('off')\n    \n    # 8. Summary statistics table\n    ax8 = fig.add_subplot(gs[3, 2])\n    ax8.axis('tight')\n    ax8.axis('off')\n    \n    # Create summary table\n    summary_data = []\n    summary_data.append(['Metric', 'Fire Sites', 'Baseline Sites'])\n    summary_data.append(['Sites', len(fire_sites), len(baseline_sites)])\n    summary_data.append(['Avg NDVI', f'{fire_means[\"NDVI\"]:.3f}', f'{baseline_means[\"NDVI\"]:.3f}'])\n    summary_data.append(['Avg NBR', f'{fire_means[\"NBR\"]:.3f}', f'{baseline_means[\"NBR\"]:.3f}'])\n    summary_data.append(['Avg Images', \n                        f'{site_stats_df[site_stats_df[\"site_type\"]==\"fire_case_study\"][\"n_images\"].mean():.0f}',\n                        f'{site_stats_df[site_stats_df[\"site_type\"]==\"baseline\"][\"n_images\"].mean():.0f}'])\n    \n    table = ax8.table(cellText=summary_data[1:], colLabels=summary_data[0],\n                     cellLoc='center', loc='center')\n    table.auto_set_font_size(False)\n    table.set_fontsize(12)\n    table.scale(1.2, 1.5)\n    \n    # Style the header\n    for i in range(3):\n        table[(0, i)].set_facecolor('#40466e')\n        table[(0, i)].set_text_props(weight='bold', color='white')\n    \n    ax8.set_title('Summary Statistics', fontsize=14, pad=20)\n    \n    plt.tight_layout()\n    return fig\n\n# Create and display the dashboard\ndashboard = create_dashboard()\nplt.show()\n\n# Save the dashboard\ndashboard_file = os.path.join(output_dir, 'satellite_processing_dashboard.png')\ndashboard.savefig(dashboard_file, dpi=300, bbox_inches='tight')\nprint(f\"\\n‚úÖ Dashboard saved to: {dashboard_file}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 11. Key Takeaways\n\nThis notebook demonstrated comprehensive satellite data processing for the NEON AOP Crosswalk system. Here are the key findings and capabilities:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Summary of key findings\nprint(\"üîç KEY TAKEAWAYS FROM SATELLITE DATA PROCESSING\\n\")\n\nprint(\"1. DATA COLLECTION & PROCESSING\")\nprint(\"   ‚úì Successfully collected Sentinel-2 and Landsat data for all NEON sites\")\nprint(\"   ‚úì Implemented cloud masking for high-quality observations\")\nprint(\"   ‚úì Calculated vegetation indices: NDVI, NBR, NDWI, EVI\")\nprint(\"   ‚úì Processed both pre- and post-fire data for fire case studies\\n\")\n\nprint(\"2. MULTI-SENSOR COMPARISON\")\nprint(\"   ‚úì Sentinel-2: Higher temporal resolution (~5 days), 10-20m spatial\")\nprint(\"   ‚úì Landsat: Lower temporal resolution (~16 days), 30m spatial\")\nprint(\"   ‚úì Both sensors show consistent vegetation patterns\")\nprint(\"   ‚úì Sentinel-2 preferred for rapid change detection\\n\")\n\nprint(\"3. FIRE IMPACT ANALYSIS\")\nprint(\"   ‚úì dNBR effectively captures fire severity\")\nprint(\"   ‚úì Fire sites show lower post-fire vegetation indices\")\nprint(\"   ‚úì Clear distinction between fire-impacted and baseline sites\")\nprint(f\"   ‚úì Example: {site} showed mean dNBR of {stats.get('dNBR_mean', 0):.3f}\\n\")\n\nprint(\"4. CROSS-SITE PATTERNS\")\nfire_vs_baseline = (fire_means['NDVI'] - baseline_means['NDVI']) / baseline_means['NDVI'] * 100\nprint(f\"   ‚úì Fire sites show {abs(fire_vs_baseline):.1f}% {'lower' if fire_vs_baseline < 0 else 'higher'} NDVI than baseline\")\nprint(f\"   ‚úì Fire sites: mean NDVI = {fire_means['NDVI']:.3f}, NBR = {fire_means['NBR']:.3f}\")\nprint(f\"   ‚úì Baseline sites: mean NDVI = {baseline_means['NDVI']:.3f}, NBR = {baseline_means['NBR']:.3f}\")\nprint(\"   ‚úì Desert sites (SRER, JORN, ONAQ) show lower overall vegetation indices\\n\")\n\nprint(\"5. DATA QUALITY & AVAILABILITY\")\nprint(f\"   ‚úì Average {site_stats_df['n_images'].mean():.0f} cloud-free images per site\")\nprint(\"   ‚úì Growing season (May-Sep) provides best coverage\")\nprint(\"   ‚úì Cloud masking essential for accurate analysis\")\nprint(\"   ‚úì Data exported and ready for AOP crosswalk\\n\")\n\nprint(\"6. APPLICATIONS FOR AOP CROSSWALK\")\nprint(\"   ‚úì Satellite data provides wall-to-wall coverage between AOP flights\")\nprint(\"   ‚úì Vegetation indices can be calibrated with AOP hyperspectral data\")\nprint(\"   ‚úì Fire severity mapping enhances AOP change detection\")\nprint(\"   ‚úì Multi-sensor approach improves temporal coverage\\n\")\n\nprint(\"7. NEXT STEPS\")\nprint(\"   ‚úì Align satellite data with AOP flight dates\")\nprint(\"   ‚úì Extract satellite data at AOP plot locations\")\nprint(\"   ‚úì Train crosswalk models to predict AOP-quality metrics\")\nprint(\"   ‚úì Validate models across fire and baseline conditions\")\n\n# Create a simple results summary\nresults_summary = {\n    'processing_date': datetime.now().strftime('%Y-%m-%d'),\n    'n_sites_processed': len(NEON_SITES),\n    'n_fire_sites': len(fire_sites),\n    'n_baseline_sites': len(baseline_sites),\n    'sensors': ['Sentinel-2', 'Landsat 8/9'],\n    'vegetation_indices': indices,\n    'mean_ndvi_fire': float(fire_means['NDVI']),\n    'mean_ndvi_baseline': float(baseline_means['NDVI']),\n    'mean_nbr_fire': float(fire_means['NBR']),\n    'mean_nbr_baseline': float(baseline_means['NBR']),\n    'export_directory': output_dir\n}\n\n# Save results summary\nsummary_file = os.path.join(output_dir, 'processing_summary.json')\nwith open(summary_file, 'w') as f:\n    json.dump(results_summary, f, indent=2)\n\nprint(f\"\\n‚úÖ Processing complete! Summary saved to: {summary_file}\")\nprint(f\"üìÅ All outputs saved to: {output_dir}\")\nprint(\"\\nüöÄ Ready for integration with AOP data in the crosswalk analysis!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Visualization Dashboard\n\nLet's create a comprehensive dashboard to visualize our satellite data processing results.",
   "metadata": {}
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}